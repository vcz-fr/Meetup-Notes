# Cloud Native Computing Foundation Bordeaux #3

## CNCF News
- New tech leaders have been appointed at CNCF in 2019 ;
- [etcd](https://coreos.com/etcd/) joined the CNCF incubator ;
- [CoreDNS](https://coredns.io/) has graduated!
- A [CVE](https://kubernetes.io/blog/2019/02/11/runc-and-cve-2019-5736/) has been discovered in RunC ;
- A translation initiative has started for the Kubernetes documentation: if you are interested, visit the [Kubernetes doc of your favorite language](https://kubernetes.io/fr/docs/home/) or fork the [website repository](https://github.com/kubernetes/website/tree/master/content)!

## Feedback on two years of production issues with Kubernetes
By [Denis Germain](https://twitter.com/zwindler), Cloud Engineer @ Lectra - [Personal Website \[FR\]](https://blog.zwindler.fr) - [Slides \[FR\]](https://blog.zwindler.fr/wp-content/uploads/2019/02/CNCF_meetup_Dans_Ton_Kube_REX_20190212.pdf)

Lectra is a company where 200+ developers are split across 22 teams including one for CI and a DevOps team. In 2015, it started its cloud & SaaS transition, which implies a progressive transition to Hign Availability by shutting down non-compatible infrastructure and migrating to micro-services.

The idea that struck right away: using Kubernetes, mostly with the Azure cloud. The Azure cloud allowed them to quickly deploy their infrastructure with [Kubespray](https://kubespray.io) or [Kubeadm](https://github.com/kubernetes/kubeadm), which are roughly similar. Today, their infrastructure is composed of seven clusters including five hosted in the Azure cloud and two on premise. They contain 50 nodes with 500 deployments and 1500 stateless pods. In two years, no major incident has held back production although some smaller ones were noticed. 

### The issues

[etcd](https://coreos.com/etcd/) is used by Kubernetes to describe cluster states. [AKS](https://docs.microsoft.com/en-us/azure/aks/), the managed Kubernetes solution from Azure uses an obsolete version of etcd - obsolete might be strong since the technology is very recent - which saturated the disks at Lectra's scale. Solution: manually migrate to a non-obsolete version of etcd.

As a reminder, in Kubernetes, the smaller unit is the Pod, which is defined in a ReplicaSet, which is defined in a Deployment. Kubernetes was not deploying pods optimally; some applications were hosted on the same node just because they were not demanding and the related nodes had more resources to spare at that moment. Solution: starting from Kubernetes 1.4, you can use [pod affinity and anti-affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity) to specify how you prefer your pods to be distributed.

